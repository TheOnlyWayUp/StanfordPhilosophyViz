{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'om' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mom\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'om' is not defined"
     ]
    }
   ],
   "source": [
    "om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from rich import print as pprint\n",
    "import aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = aiohttp.ClientSession(headers={'user-agent': 'om'}, raise_for_status=True)\n",
    "\n",
    "async def fetch_html(url: str) -> str:\n",
    "    async with session.get(url) as response:\n",
    "        return await response.text()\n",
    "\n",
    "base_url = \"https://plato.stanford.edu/\"\n",
    "toc = BeautifulSoup(await fetch_html(base_url + \"projected-contents.html\"))\n",
    "\n",
    "print(\"Retrieved Table of Contents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scrape = [base_url + a.attrs.get('href') for a in toc.find_all('a') if a.attrs.get('href') and a.attrs.get('href').startswith('entries')]\n",
    "# to_scrape = to_scrape[:5]\n",
    "\n",
    "print(f\"Found {len(to_scrape)} articles to scrape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "all_documents: List[Document] = []\n",
    "for url in to_scrape:\n",
    "    article = BeautifulSoup(await fetch_html(url))\n",
    "\n",
    "    title = article.title.text.split('(')[0].strip()\n",
    "    body = article.find('div', {'id': 'main-text'})\n",
    "\n",
    "    # docs: https://python.langchain.com/docs/how_to/HTML_header_metadata_splitter/#usage-examples\n",
    "    splitter = HTMLHeaderTextSplitter([('h1', 'section'), ('h2', 'subsection')], return_each_element=True)  \n",
    "    documents = splitter.split_text(str(body))\n",
    "\n",
    "    for document in documents:\n",
    "        document.metadata['title'] = title\n",
    "        document.metadata['url'] = url\n",
    "\n",
    "    all_documents += documents\n",
    "\n",
    "    print(f\"Retrieved {title} as {len(documents)} documents\")\n",
    "\n",
    "print(f\"Completed fetching, created {len(all_documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model = HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\")  # 512 tokens\n",
    "\n",
    "embeddings = model.embed_documents([document.page_content for document in all_documents])\n",
    "\n",
    "print(\"Embedded documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs: https://github.com/cmudig/emblaze#examples\n",
    "\n",
    "import emblaze\n",
    "from emblaze.utils import Field, ProjectionTechnique\n",
    "\n",
    "emb = emblaze.Embedding({Field.POSITION: embeddings, Field.COLOR: [doc.metadata['title'] for doc in all_documents]})\n",
    "emb.compute_neighbors(metric='cosine')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction\n",
    "variants = emblaze.EmbeddingSet([\n",
    "    emb.project(method=ProjectionTechnique.TSNE),  # uhh i forgot how this works\n",
    "    emb.project(method=ProjectionTechnique.PCA)  # PCA is Principal Compoenent Analysis, our embeddings of 384 dimensions are reduced to 2 dimensions, PCA finds the 2 dimensions with the most variation and uses them as 'anchors' to reorganize the points to preserve relationships, but in 2D\n",
    "])\n",
    "\n",
    "print(\"Reduced dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb0a5ff88d444afa250213c5c1a5514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(colorScheme='tableau', data={'data': [{'_format': 'compressed', '_idtype': 'u2', '_length': 386, 'ids':â€¦"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thumbnails = emblaze.TextThumbnails(descriptions=[doc.metadata['title'] for doc in all_documents], names=[doc.metadata.get(\"subsection\") for doc in all_documents])\n",
    "w = emblaze.Viewer(embeddings=variants, thumbnails=thumbnails)\n",
    "w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
